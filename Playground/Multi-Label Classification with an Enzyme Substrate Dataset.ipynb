{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-04T02:42:23.718808500Z",
     "start_time": "2023-08-04T02:42:20.985080400Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "import autogluon\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "import autogluon.core as ag\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "def seed_everything(seed): # 作用是固定随机种子，使得每次运行模型的时候，结果都是一样的\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "original = pd.read_csv(\"mixed_desc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def setup_outputdir(path, warn_if_exist=True, create_dir=True, path_suffix=None): \n",
    "    \"\"\"\n",
    "    作用是创建一个文件夹，用来存放模型\n",
    "    :param path: \n",
    "    :param warn_if_exist: \n",
    "    :param create_dir: \n",
    "    :param path_suffix: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    if path:\n",
    "        assert isinstance(path, (str, Path)), f\"Only str and pathlib.Path types are supported for path, got {path} of type {type(path)}.\"\n",
    "    if path_suffix is None:\n",
    "        path_suffix = \"\"\n",
    "    if path_suffix and path_suffix[-1] == os.path.sep:\n",
    "        path_suffix = path_suffix[:-1]\n",
    "    if path is not None:\n",
    "        path = f\"{path}{path_suffix}\"\n",
    "    if path is None:\n",
    "        utcnow = datetime.utcnow()\n",
    "        timestamp = utcnow.strftime(\"%Y%m%d_%H%M%S\")\n",
    "        path = f\"AutogluonModels{os.path.sep}ag-{timestamp}{path_suffix}{os.path.sep}\"\n",
    "        for i in range(1, 1000):\n",
    "            try:\n",
    "                if create_dir:\n",
    "                    os.makedirs(path, exist_ok=False)\n",
    "                    break\n",
    "                else:\n",
    "                    if os.path.isdir(path):\n",
    "                        raise FileExistsError\n",
    "                    break\n",
    "            except FileExistsError:\n",
    "                path = f\"AutogluonModels{os.path.sep}ag-{timestamp}-{i:03d}{path_suffix}{os.path.sep}\"\n",
    "        else:\n",
    "            raise RuntimeError(\"more than 1000 jobs launched in the same second\")\n",
    "        logger.log(25, f'No path specified. Models will be saved in: \"{path}\"')\n",
    "    elif warn_if_exist:\n",
    "        try:\n",
    "            if create_dir:\n",
    "                os.makedirs(path, exist_ok=False)\n",
    "            elif os.path.isdir(path):\n",
    "                raise FileExistsError\n",
    "        except FileExistsError:\n",
    "            logger.warning(f'Warning: path already exists! This predictor may overwrite an existing predictor! path=\"{path}\"')\n",
    "    path = os.path.expanduser(path)  # 作用是将path中包含的\"~\"和\"~user\"转换成用户目录\n",
    "    if path[-1] != os.path.sep:\n",
    "        path = path + os.path.sep\n",
    "    return path"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:04:50.362857800Z",
     "start_time": "2023-08-04T03:04:50.331401900Z"
    }
   },
   "id": "2d35805408abafb2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "from autogluon.core.utils.loaders import load_pkl # 作用是加载pkl文件\n",
    "from autogluon.core.utils.savers import save_pkl\n",
    "import os.path\n",
    "\n",
    "\n",
    "class MultilabelPredictor(): \n",
    "    multi_predictor_file = 'multilabel_predictor.pkl'\n",
    "\n",
    "    def __init__(self, labels, path=None, problem_types=None, eval_metrics=None, consider_labels_correlation=False, **kwargs):\n",
    "        if len(labels) < 2:\n",
    "            raise ValueError(\"MultilabelPredictor is only intended for predicting MULTIPLE labels (columns), use TabularPredictor for predicting one label (column).\")\n",
    "        if (problem_types is not None) and (len(problem_types) != len(labels)):\n",
    "            raise ValueError(\"If provided, `problem_types` must have same length as `labels`\")\n",
    "        if (eval_metrics is not None) and (len(eval_metrics) != len(labels)):\n",
    "            raise ValueError(\"If provided, `eval_metrics` must have same length as `labels`\")\n",
    "        self.path = setup_outputdir(path, warn_if_exist=False)\n",
    "        self.labels = labels\n",
    "        self.consider_labels_correlation = consider_labels_correlation\n",
    "        self.predictors = {}  # key = label, value = TabularPredictor or str path to the TabularPredictor for this label\n",
    "        if eval_metrics is None:\n",
    "            self.eval_metrics = {}\n",
    "        else:\n",
    "            self.eval_metrics = {labels[i] : eval_metrics[i] for i in range(len(labels))}\n",
    "        problem_type = None\n",
    "        eval_metric = None\n",
    "        for i in range(len(labels)):\n",
    "            label = labels[i]\n",
    "            path_i = self.path + \"Predictor_\" + label\n",
    "            if problem_types is not None:\n",
    "                problem_type = problem_types[i]\n",
    "            if eval_metrics is not None:\n",
    "                eval_metric = eval_metrics[i]\n",
    "            self.predictors[label] = TabularPredictor(label=label, problem_type=problem_type, eval_metric=eval_metric, path=path_i, **kwargs)\n",
    "\n",
    "    def fit(self, train_data, tuning_data=None, **kwargs):\n",
    "        if isinstance(train_data, str):\n",
    "            train_data = TabularDataset(train_data)\n",
    "        if tuning_data is not None and isinstance(tuning_data, str):\n",
    "            tuning_data = TabularDataset(tuning_data)\n",
    "        train_data_og = train_data.copy()\n",
    "        if tuning_data is not None:\n",
    "            tuning_data_og = tuning_data.copy()\n",
    "        else:\n",
    "            tuning_data_og = None\n",
    "        save_metrics = len(self.eval_metrics) == 0\n",
    "        for i in range(len(self.labels)):\n",
    "            label = self.labels[i]\n",
    "            predictor = self.get_predictor(label)\n",
    "            if not self.consider_labels_correlation:\n",
    "                labels_to_drop = [l for l in self.labels if l != label]\n",
    "            else:\n",
    "                labels_to_drop = [self.labels[j] for j in range(i+1, len(self.labels))]\n",
    "            train_data = train_data_og.drop(labels_to_drop, axis=1)\n",
    "            if tuning_data is not None:\n",
    "                tuning_data = tuning_data_og.drop(labels_to_drop, axis=1)\n",
    "            print(f\"Fitting TabularPredictor for label: {label} ...\")\n",
    "            predictor.fit(train_data=train_data, tuning_data=tuning_data, **kwargs)\n",
    "            self.predictors[label] = predictor.path\n",
    "            if save_metrics:\n",
    "                self.eval_metrics[label] = predictor.eval_metric\n",
    "        self.save()\n",
    "\n",
    "    def predict(self, data, **kwargs):\n",
    "        return self._predict(data, as_proba=False, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        return self._predict(data, as_proba=True, **kwargs)\n",
    "\n",
    "    def evaluate(self, data, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        eval_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Evaluating TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            eval_dict[label] = predictor.evaluate(data, **kwargs)\n",
    "            if self.consider_labels_correlation:\n",
    "                data[label] = predictor.predict(data, **kwargs)\n",
    "        return eval_dict\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save MultilabelPredictor to disk. \"\"\"\n",
    "        for label in self.labels:\n",
    "            if not isinstance(self.predictors[label], str):\n",
    "                self.predictors[label] = self.predictors[label].path\n",
    "        save_pkl.save(path=self.path+self.multi_predictor_file, object=self)\n",
    "        print(f\"MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('{self.path}')\")\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path):\n",
    "        path = os.path.expanduser(path)\n",
    "        if path[-1] != os.path.sep:\n",
    "            path = path + os.path.sep\n",
    "        return load_pkl.load(path=path+cls.multi_predictor_file)\n",
    "\n",
    "    def get_predictor(self, label):\n",
    "        predictor = self.predictors[label]\n",
    "        if isinstance(predictor, str):\n",
    "            return TabularPredictor.load(path=predictor)\n",
    "        return predictor\n",
    "\n",
    "    def _get_data(self, data):\n",
    "        if isinstance(data, str):\n",
    "            return TabularDataset(data)\n",
    "        return data.copy()\n",
    "\n",
    "    def _predict(self, data, as_proba=False, **kwargs):\n",
    "        data = self._get_data(data)\n",
    "        if as_proba:\n",
    "            predproba_dict = {}\n",
    "        for label in self.labels:\n",
    "            print(f\"Predicting with TabularPredictor for label: {label} ...\")\n",
    "            predictor = self.get_predictor(label)\n",
    "            if as_proba:\n",
    "                predproba_dict[label] = predictor.predict_proba(data, as_multiclass=True, **kwargs)\n",
    "            data[label] = predictor.predict(data, **kwargs)\n",
    "        if not as_proba:\n",
    "            return data[self.labels]\n",
    "        else:\n",
    "            return predproba_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:05:58.821498100Z",
     "start_time": "2023-08-04T03:05:58.782941600Z"
    }
   },
   "id": "9ffcc3747780b5d2"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Original\n",
    "cols=['CIDs', 'BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v','Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1','FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha','HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex','NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7','PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9','fr_COO', 'fr_COO2', 'EC1_EC2_EC3_EC4_EC5_EC6'] # cols的作用是只保留这些列\n",
    "original = original.loc[:,cols] # 只保留cols中的列\n",
    "original[['EC1', 'EC2']] = original['EC1_EC2_EC3_EC4_EC5_EC6'].str.split('_', expand=True).iloc[:,:2].astype(int) # 将EC1_EC2_EC3_EC4_EC5_EC6列按照_分割，取前两列，转换为int类型，赋值给EC1和EC2列\n",
    "original.drop(columns = ['EC1_EC2_EC3_EC4_EC5_EC6','CIDs'], inplace=True) \n",
    "original['id'] = original.reset_index().index # 重置index，并将index赋值给id列\n",
    "# Train\n",
    "train.drop(columns = ['EC3', 'EC4', 'EC5', 'EC6'], inplace=True)\n",
    "\n",
    "train = pd.concat([train, original])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:06:33.637009300Z",
     "start_time": "2023-08-04T03:06:33.573728800Z"
    }
   },
   "id": "f85ef024c3c331d3"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data = TabularDataset(train)\n",
    "test_data = TabularDataset(test)\n",
    "\n",
    "train_data.drop('id',axis = 1, inplace = True)\n",
    "test_data.drop('id',axis = 1, inplace = True)\n",
    "\n",
    "labels = ['EC1', 'EC2']\n",
    "problem_types = ['regression', 'regression'] \n",
    "eval_metrics = ['roc_auc', 'roc_auc']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:07:07.412931400Z",
     "start_time": "2023-08-04T03:07:07.318243200Z"
    }
   },
   "id": "7ae889ad26b5319"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 43200s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230804_030758\\Predictor_EC1\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    15877\n",
      "Train Data Columns: 31\n",
      "Label Column: EC1\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    5269.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.94 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n",
      "\t\t('int', [])   :  3 | ['NumHeteroatoms', 'fr_COO', 'fr_COO2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n",
      "\t\t('int', [])   :  3 | ['NumHeteroatoms', 'fr_COO', 'fr_COO2']\n",
      "\t0.1s = Fit runtime\n",
      "\t31 features in original data used to generate 31 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.94 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 14289, Val Rows: 1588\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 43199.92s of the 43199.92s of remaining time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: EC1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t-0.4859\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.66s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 43198.07s of the 43198.07s of remaining time.\n",
      "\t-0.4873\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 43197.98s of the 43197.98s of remaining time.\n",
      "\t-0.4351\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 43197.3s of the 43197.3s of remaining time.\n",
      "\t-0.4373\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 43196.95s of the 43196.95s of remaining time.\n",
      "\t-0.4431\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.66s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 43189.16s of the 43189.16s of remaining time.\n",
      "\t-0.4357\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.26s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 43186.89s of the 43186.89s of remaining time.\n",
      "\t-0.4425\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 43185.49s of the 43185.49s of remaining time.\n",
      "No improvement since epoch 1: early stopping\n",
      "\t-0.4373\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.38s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 43174.06s of the 43174.06s of remaining time.\n",
      "\t-0.4368\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 43173.3s of the 43173.3s of remaining time.\n",
      "\t-0.5028\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.46s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 43164.81s of the 43164.81s of remaining time.\n",
      "\t-0.4388\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 4319.99s of the 43163.62s of remaining time.\n",
      "\t-0.4341\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 36.59s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230804_030758\\Predictor_EC1\\\")\n",
      "Beginning AutoGluon training ... Time limit = 43200s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20230804_030758\\Predictor_EC2\\\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.9.16\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22621\n",
      "Train Data Rows:    15877\n",
      "Train Data Columns: 31\n",
      "Label Column: EC2\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    4954.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.94 MB (0.1% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n",
      "\t\t('int', [])   :  3 | ['NumHeteroatoms', 'fr_COO', 'fr_COO2']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 28 | ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', ...]\n",
      "\t\t('int', [])   :  3 | ['NumHeteroatoms', 'fr_COO', 'fr_COO2']\n",
      "\t0.1s = Fit runtime\n",
      "\t31 features in original data used to generate 31 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 3.94 MB (0.1% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 14289, Val Rows: 1588\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 43199.92s of the 43199.92s of remaining time.\n",
      "\t-0.4349\t = Validation score   (-root_mean_squared_error)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting TabularPredictor for label: EC2 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.02s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 43199.83s of the 43199.82s of remaining time.\n",
      "\t-0.4352\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 43199.75s of the 43199.74s of remaining time.\n",
      "\t-0.4055\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 43199.4s of the 43199.4s of remaining time.\n",
      "\t-0.406\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.33s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 43199.06s of the 43199.06s of remaining time.\n",
      "\t-0.4087\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.24s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 43189.68s of the 43189.68s of remaining time.\n",
      "\t-0.4051\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 43187.83s of the 43187.83s of remaining time.\n",
      "\t-0.4048\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.42s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 43186.27s of the 43186.27s of remaining time.\n",
      "\t-0.4054\t = Validation score   (-root_mean_squared_error)\n",
      "\t31.07s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 43155.14s of the 43155.14s of remaining time.\n",
      "\t-0.4052\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 43153.93s of the 43153.93s of remaining time.\n",
      "\t-0.4564\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.55s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 43132.34s of the 43132.34s of remaining time.\n",
      "\t-0.4056\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 4319.99s of the 43131.44s of remaining time.\n",
      "\t-0.4022\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 68.79s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20230804_030758\\Predictor_EC2\\\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultilabelPredictor saved to disk. Load with: MultilabelPredictor.load('AutogluonModels\\ag-20230804_030758\\')\n"
     ]
    }
   ],
   "source": [
    "multi_predictor = MultilabelPredictor(labels=labels, problem_types=problem_types) \n",
    "multi_predictor.fit(train_data,time_limit=3600*12)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:09:43.756349600Z",
     "start_time": "2023-08-04T03:07:58.276063700Z"
    }
   },
   "id": "424a3c351decc103"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                  model  score_val  pred_time_val   fit_time  \\\n0   WeightedEnsemble_L2  -0.434096       0.136504  20.651369   \n1            LightGBMXT  -0.435081       0.003000   0.667373   \n2              CatBoost  -0.435684       0.005003   2.257308   \n3               XGBoost  -0.436835       0.004519   0.741095   \n4              LightGBM  -0.437272       0.002005   0.342847   \n5       NeuralNetFastAI  -0.437279       0.031249  11.383404   \n6         LightGBMLarge  -0.438752       0.002998   1.138089   \n7         ExtraTreesMSE  -0.442542       0.040089   1.256980   \n8       RandomForestMSE  -0.443106       0.043152   7.662980   \n9        KNeighborsUnif  -0.485949       0.172225   1.664919   \n10       KNeighborsDist  -0.487297       0.054585   0.024100   \n11       NeuralNetTorch  -0.502840       0.021269   8.458560   \n\n    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n0                 0.000000           0.172418            2       True   \n1                 0.003000           0.667373            1       True   \n2                 0.005003           2.257308            1       True   \n3                 0.004519           0.741095            1       True   \n4                 0.002005           0.342847            1       True   \n5                 0.031249          11.383404            1       True   \n6                 0.002998           1.138089            1       True   \n7                 0.040089           1.256980            1       True   \n8                 0.043152           7.662980            1       True   \n9                 0.172225           1.664919            1       True   \n10                0.054585           0.024100            1       True   \n11                0.021269           8.458560            1       True   \n\n    fit_order  \n0          12  \n1           3  \n2           6  \n3           9  \n4           4  \n5           8  \n6          11  \n7           7  \n8           5  \n9           1  \n10          2  \n11         10  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>score_val</th>\n      <th>pred_time_val</th>\n      <th>fit_time</th>\n      <th>pred_time_val_marginal</th>\n      <th>fit_time_marginal</th>\n      <th>stack_level</th>\n      <th>can_infer</th>\n      <th>fit_order</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>WeightedEnsemble_L2</td>\n      <td>-0.434096</td>\n      <td>0.136504</td>\n      <td>20.651369</td>\n      <td>0.000000</td>\n      <td>0.172418</td>\n      <td>2</td>\n      <td>True</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>LightGBMXT</td>\n      <td>-0.435081</td>\n      <td>0.003000</td>\n      <td>0.667373</td>\n      <td>0.003000</td>\n      <td>0.667373</td>\n      <td>1</td>\n      <td>True</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CatBoost</td>\n      <td>-0.435684</td>\n      <td>0.005003</td>\n      <td>2.257308</td>\n      <td>0.005003</td>\n      <td>2.257308</td>\n      <td>1</td>\n      <td>True</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XGBoost</td>\n      <td>-0.436835</td>\n      <td>0.004519</td>\n      <td>0.741095</td>\n      <td>0.004519</td>\n      <td>0.741095</td>\n      <td>1</td>\n      <td>True</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LightGBM</td>\n      <td>-0.437272</td>\n      <td>0.002005</td>\n      <td>0.342847</td>\n      <td>0.002005</td>\n      <td>0.342847</td>\n      <td>1</td>\n      <td>True</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NeuralNetFastAI</td>\n      <td>-0.437279</td>\n      <td>0.031249</td>\n      <td>11.383404</td>\n      <td>0.031249</td>\n      <td>11.383404</td>\n      <td>1</td>\n      <td>True</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LightGBMLarge</td>\n      <td>-0.438752</td>\n      <td>0.002998</td>\n      <td>1.138089</td>\n      <td>0.002998</td>\n      <td>1.138089</td>\n      <td>1</td>\n      <td>True</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ExtraTreesMSE</td>\n      <td>-0.442542</td>\n      <td>0.040089</td>\n      <td>1.256980</td>\n      <td>0.040089</td>\n      <td>1.256980</td>\n      <td>1</td>\n      <td>True</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RandomForestMSE</td>\n      <td>-0.443106</td>\n      <td>0.043152</td>\n      <td>7.662980</td>\n      <td>0.043152</td>\n      <td>7.662980</td>\n      <td>1</td>\n      <td>True</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>KNeighborsUnif</td>\n      <td>-0.485949</td>\n      <td>0.172225</td>\n      <td>1.664919</td>\n      <td>0.172225</td>\n      <td>1.664919</td>\n      <td>1</td>\n      <td>True</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>KNeighborsDist</td>\n      <td>-0.487297</td>\n      <td>0.054585</td>\n      <td>0.024100</td>\n      <td>0.054585</td>\n      <td>0.024100</td>\n      <td>1</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>NeuralNetTorch</td>\n      <td>-0.502840</td>\n      <td>0.021269</td>\n      <td>8.458560</td>\n      <td>0.021269</td>\n      <td>8.458560</td>\n      <td>1</td>\n      <td>True</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_class = multi_predictor.get_predictor('EC1') # 意思是取出EC1的predictor\n",
    "predictor_class.leaderboard(silent=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:10:48.639045800Z",
     "start_time": "2023-08-04T03:10:48.556040200Z"
    }
   },
   "id": "49de061dcee4a14e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting with TabularPredictor for label: EC1 ...\n",
      "Predicting with TabularPredictor for label: EC2 ...\n"
     ]
    }
   ],
   "source": [
    "model_pred = multi_predictor.predict(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:11:46.951583800Z",
     "start_time": "2023-08-04T03:11:45.560050Z"
    }
   },
   "id": "8f28fe0a30f4e7f9"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "        EC1       EC2\n0  0.411515  0.764463\n1  0.817132  0.776930\n2  0.791945  0.734284\n3  0.763807  0.787167\n4  0.816324  0.779002",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EC1</th>\n      <th>EC2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.411515</td>\n      <td>0.764463</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.817132</td>\n      <td>0.776930</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.791945</td>\n      <td>0.734284</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.763807</td>\n      <td>0.787167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.816324</td>\n      <td>0.779002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pred.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:14:25.592408500Z",
     "start_time": "2023-08-04T03:14:25.471641200Z"
    }
   },
   "id": "9c7759c559fb4e99"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      id       EC1       EC2\n0  14838  0.411515  0.764463\n1  14839  0.817132  0.776930\n2  14840  0.791945  0.734284\n3  14841  0.763807  0.787167\n4  14842  0.816324  0.779002",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>EC1</th>\n      <th>EC2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>14838</td>\n      <td>0.411515</td>\n      <td>0.764463</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>14839</td>\n      <td>0.817132</td>\n      <td>0.776930</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14840</td>\n      <td>0.791945</td>\n      <td>0.734284</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14841</td>\n      <td>0.763807</td>\n      <td>0.787167</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14842</td>\n      <td>0.816324</td>\n      <td>0.779002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.concat([test, model_pred], axis=1) \n",
    "test.drop(columns = ['BertzCT', 'Chi1', 'Chi1n', 'Chi1v', 'Chi2n', 'Chi2v', 'Chi3v','Chi4n', 'EState_VSA1', 'EState_VSA2', 'ExactMolWt', 'FpDensityMorgan1','FpDensityMorgan2', 'FpDensityMorgan3', 'HallKierAlpha','HeavyAtomMolWt', 'Kappa3', 'MaxAbsEStateIndex', 'MinEStateIndex','NumHeteroatoms', 'PEOE_VSA10', 'PEOE_VSA14', 'PEOE_VSA6', 'PEOE_VSA7','PEOE_VSA8', 'SMR_VSA10', 'SMR_VSA5', 'SlogP_VSA3', 'VSA_EState9','fr_COO', 'fr_COO2'], inplace=True)\n",
    "test.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:17:13.454964200Z",
     "start_time": "2023-08-04T03:17:13.361458500Z"
    }
   },
   "id": "3bff999250309fb6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 保存\n",
    "submission = test[['id', 'EC1', 'EC2']]\n",
    "submission.to_csv('submission.csv', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-04T03:19:12.688617Z",
     "start_time": "2023-08-04T03:19:12.634955100Z"
    }
   },
   "id": "c01b1785626fa516"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c61118938b691c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
